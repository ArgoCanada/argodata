---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%",
  dpi = 300
)

library(argodata)
library(tidyverse)

argo_set_cache_dir("cache-dev")
options(argodata.max_global_cache_age = Inf)
options(argodata.max_data_cache_age = Inf)

argo_global_prof()
```

# argodata

<!-- badges: start -->
[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://www.tidyverse.org/lifecycle/#experimental)
[![R build status](https://github.com/ArgoCanada/argodata/workflows/R-CMD-check/badge.svg)](https://github.com/ArgoCanada/argodata/actions)
[![Codecov test coverage](https://codecov.io/gh/ArgoCanada/argodata/branch/master/graph/badge.svg)](https://codecov.io/gh/ArgoCanada/argodata?branch=master)
<!-- badges: end -->

The goal of argodata is to provide a data frame-based interface to data generated by the [Argo floats program](https://argo.ucsd.edu/).

## Installation

You can install the development version from [GitHub](https://github.com/) with:

``` r
# install.packages("remotes")
remotes::install_github("ArgoCanada/argodata")
```

The argodata package downloads files from the [FTP and HTTPS mirrors](http://www.argodatamgt.org/Access-to-data/Access-via-FTP-or-HTTPS-on-GDAC), caches them, and loads them into R. You can set the mirror using `argo_set_mirror()` and the cache directory using `argo_set_cache_dir()`:

```{r, eval = FALSE}
argo_set_mirror("https://data-argo.ifremer.fr/")
argo_set_cache_dir("my/argo/cache")
```

Optionally, you can set `options(argodata.cache_dir = "my/argo/cache")` in your .Rprofile to persist this value between R sessions (see `usethis::edit_r_profile()`). Cached files are used indefinitely by default because of the considerable time it takes to refresh them. If you do use a persistent cache, you should at least update the index files regularly using `argo_update_global()` (data files are also updated occasionally; update these using `argo_update_data()`).

## Example

The main workflow supported by argodata is:

- Start with `argo_global_prof()`, `argo_global_traj()`, or `argo_global_meta()`
- Use `argo_filter_radius()`, other `argo_filter_*()` functions, or `dplyr::filter()` to subset the index
- Use `argo_prof_levels()`, `argo_traj_measurement()`, or `argo_meta_missions()` to extract and row-bind tables for all files in the index

```{r example}
library(tidyverse)
library(argodata)

# filter profile index using search criteria
prof_lab_may_2020 <- argo_global_prof() %>%
  argo_filter_rect(50, 60, -60, -50) %>% 
  filter(
    lubridate::year(date) == 2020, 
    lubridate::month(date) == 5
  )

# download, cache, and load NetCDF files
levels_lab_may_2020 <- prof_lab_may_2020 %>% 
  argo_prof_levels()

# plot!
levels_lab_may_2020 %>% 
  filter(psal_qc == 1) %>% 
  ggplot(aes(x = psal, y = pres, col = temp)) +
  geom_point() +
  scale_y_reverse() +
  theme_bw()
```

See the reference for `argo_prof_levels()` for more ways to load Argo profiles from `argo_global_prof()`, `argo_global_bio_prof()` and `argo_global_synthetic_prof()`; see `argo_traj_measurement()` for ways to load Argo trajectories from `argo_global_traj()` or `argo_global_bio_traj()`; see `argo_meta_missions()` for ways to load float meta from `argo_global_meta()`; and see `argo_info()` and `argo_vars()` for ways to load arbitrary metadata from Argo NetCDF files.

## Advanced

The argodata package also exports the low-level readers it uses to produce tables from Argo NetCDF files. You can access these using `argo_read_*()` functions.

```{r}
prof_file <- system.file(
  "cache-test/dac/csio/2900313/profiles/D2900313_000.nc",
  package = "argodata"
)

argo_read_prof_levels(prof_file)
```
