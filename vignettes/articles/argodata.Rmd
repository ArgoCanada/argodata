---
title: "Get Started with argodata"
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%",
  dpi = 300
)

# when rendering articles, this causes tibble printing to be ugly
options(crayon.enabled = FALSE)

library(argodata)

# this is a cheap way to avoid putting 'magrittr' in Suggests
`%>%` <- testthat::`%>%`

# load index files quietly
argo_global_meta()
argo_global_prof()
argo_global_tech()
argo_global_traj()

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

The argodata package was designed to work with the [tidyverse](https://tidyverse.org) family of packages, for which learning materials are available in [English](https://r4ds.had.co.nz), [German](https://oreilly.de/produkt/r-fuer-data-science/), and Portuguese.

```{r, eval=FALSE}
library(tidyverse)
library(argodata)
```

## Index files

The `argo_global_*()` functions load the index files that list the locations of other files on the mirror:

```{r}
library(argodata)
argo_global_meta()
argo_global_prof()
argo_global_tech()
argo_global_traj()
```

## Argo profiles

You can load profile data by filtering `argo_global_prof()` and piping to `argo_prof_levels()` (one row per level sampled) or `argo_prof_prof()` (one row per profile):

```{r}
argo_global_prof() %>% 
  tail(100) %>% 
  argo_prof_levels()

argo_global_prof() %>% 
  tail(100) %>% 
  argo_prof_prof()
```

## Argo trajectories

Similarly, you can load trajectory data by filtering `argo_global_traj()` and piping to `argo_traj_meas()` and/or `argo_traj_cycle()`:

```{r}
argo_global_traj() %>% 
  tail(10) %>% 
  argo_traj_meas()

argo_global_traj() %>% 
  tail(10) %>% 
  argo_traj_cycle()
```

## Reading Argo NetCDF files

If you have previously downloaded Argo data, you can use `argo_read_*()` functions:

```{r}
(profile_nc <- argo_download("dac/nmdis/2901633/profiles/R2901633_070.nc"))
argo_read_prof_levels(profile_nc)
```

Documentation for Argo variable names, units, and more are available from the [Argo Data Management Documentation page](http://www.argodatamgt.org/Documentation).

## Cache management

Each Argo floats mirror is home to over 250 GB of data organized in millions of files! The argodata package caches all files that it downloads, which you can set to a cache that persists between sessions. If you have a [local mirror updated using rsync](http://www.argodatamgt.org/Access-to-data/Argo-GDAC-synchronization-service) you can pass this directory to `argo_set_mirror()`, which can also be used to switch between the various mirrors provided by GDAC.

```{r, eval=FALSE}
argo_set_cache_dir("path/to/cache")
argo_set_mirror("ftp://usgodae.org/pub/outgoing/argo")
argo_set_mirror("path/to/local/argo")
```

Because downloaded files are cached indefinitely by default, you are recommended to use a new cache for each project that requires an internally-consistent set of Argo files or update your cache on a regular basis. If you do use a persistent cache, you should at least update the index files regularly using `argo_update_global()` (data files are also updated occasionally; update these using `argo_update_data()`). You can also override the defaults by passing `download = TRUE` to functions that load data or set `options(argodata.max_data_cache_age = XX)`, where `XX` a value in hours. Use `Inf` to always use the cached version of a file or `-Inf` to never use the cached version.

```{r, eval=FALSE}
argo_update_global()
argo_update_data()
argo_global_prof(download = TRUE)
options(argodata.max_global_cache_age = Inf)
options(argodata.max_data_cache_age = Inf)
```
